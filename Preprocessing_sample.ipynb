{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4464c0cf-feaf-47c7-be5e-8deb059081b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc4dff6-45b1-4786-a2df-e4436faaf854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab3114-cebc-4509-a578-1f9a54f76518",
   "metadata": {},
   "source": [
    "FILLING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5d7f7f-c5ff-4c01-8273-86a6cb0ad3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import shapiro,ks_2samp,norm\n",
    "from scipy.spatial.distance import cdist\n",
    "import math\n",
    "\n",
    "class Preprocessor:\n",
    "\n",
    "    # Attributes: df (Original DataFrame),  descriptor (Dataframe containing information about Null Values and Feature data type)\n",
    "    # Methods : Called from outside: __inti__(df), fillNull()\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.df=df.copy()\n",
    "        self.descriptor=self.generateDescriptor()\n",
    "    \n",
    "    def generateDescriptor(self):    # Generates descriptor df\n",
    "        descriptor_df = pd.DataFrame(self.df.isnull().sum())\n",
    "        descriptor_df[1] = round(descriptor_df[0]/self.df.shape[0],2)*100\n",
    "        isNumerical=[]\n",
    "        for column in self.df.columns:\n",
    "            if self.df[column].dtype == 'int64' or self.df[column].dtype == 'float64':\n",
    "                isNumerical.append(1)\n",
    "            else:\n",
    "                isNumerical.append(0)\n",
    "        descriptor_df[2]=isNumerical\n",
    "        return descriptor_df\n",
    "\n",
    "    def checkDistribution(self,series):    # Labels feature distribution as Normal or Skewed\n",
    "        if abs(series.skew())<0.5:\n",
    "            return \"normal\"\n",
    "        else:\n",
    "            if series.shape[0]<5000:\n",
    "                stat,p = shapiro(series)\n",
    "            else:\n",
    "                mu,sigma=series.mean(),series.std()\n",
    "                stat,p = ks_2samp(series,norm.rvs(loc=mu,scale=sigma,size=len(series)))\n",
    "            if p>0.05:\n",
    "                return \"normal\"\n",
    "            else:\n",
    "                return \"skewed\"    \n",
    "\n",
    "    def is_id_column(self,feature_series):    # Checks if feature is ID type\n",
    "        value_range = feature_series.max() - feature_series.min()\n",
    "        unique_count = feature_series.nunique()\n",
    "        if unique_count == len(feature_series):\n",
    "            if abs(value_range - unique_count) < 2:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def knnImpute(self,df,descriptor_df,feature):    # KNN imputation based on categorical or numerical feature\n",
    "        neighbour_features = [\n",
    "            it for it in descriptor_df.index\n",
    "            if descriptor_df[0][it] == 0\n",
    "            and descriptor_df[2][it] == 1\n",
    "            and not self.is_id_column(df[it])\n",
    "            ]\n",
    "    \n",
    "        neighbour_df=df[neighbour_features]\n",
    "        non_null=neighbour_df[df[feature].notna()]\n",
    "        null=neighbour_df[df[feature].isna()]\n",
    "        norm_min=neighbour_df.min()\n",
    "        norm_range=neighbour_df.max()-neighbour_df.min()\n",
    "        norm_range.replace(0,1e-9,inplace=True)\n",
    "        non_null=(non_null-norm_min)/norm_range\n",
    "        null=(null-norm_min)/norm_range\n",
    "        distances = pd.DataFrame(cdist(null,non_null,metric='euclidean'))\n",
    "        k=math.ceil(math.sqrt(non_null.shape[0]))\n",
    "        k_nearest_indices= pd.DataFrame(np.argsort(distances,axis=1)).iloc[:,:k]\n",
    "        \n",
    "        for enumerated_null_index,df_index in enumerate(null.index):\n",
    "            enumerated_non_null_indices=k_nearest_indices.loc[enumerated_null_index]\n",
    "            true_df_indices=non_null.iloc[enumerated_non_null_indices].index\n",
    "            neighbour_values = df[feature].loc[true_df_indices]\n",
    "            if descriptor_df[2][feature]==1 and self.df[feature].nunique()/len(self.df[feature])>0.05:\n",
    "                df.loc[df_index, feature] = neighbour_values.mean()\n",
    "            else:\n",
    "                df.loc[df_index, feature] = neighbour_values.mode().iloc[0]\n",
    "        \n",
    "    def fillNull(self):\n",
    "        for feature in self.descriptor.index:\n",
    "            \n",
    "            if self.descriptor[1][feature]>30:    # Feature has more than 30% null values\n",
    "                self.df.drop(feature,axis=1,inplace=True)    # Remove feature\n",
    "                self.descriptor = self.generateDescriptor()    # Remake descriptor df\n",
    "                continue\n",
    "                \n",
    "            if self.descriptor[2][feature]==1:    # Numerical feature\n",
    "                \n",
    "                if self.descriptor[1][feature]>5:    # Null values between 5-30%\n",
    "                    self.knnImpute(self.df,self.descriptor,feature)    # Use KNN\n",
    "                    \n",
    "                else:    # Null values between less than 5%\n",
    "                    if self.df[feature].nunique()/len(self.df[feature])<0.05:    # Ordinal Feature (Discrete Finite numerical)\n",
    "                        self.df.loc[:, feature] = self.df[feature].fillna(self.df[feature].mode().iloc[0]).copy()   # Fill with mode\n",
    "                        \n",
    "                    elif self.checkDistribution(self.df[feature]) == 'normal':    # Normal numerical fetaure\n",
    "                        self.df.loc[:, feature] = self.df[feature].fillna(self.df[feature].mean()).copy()    # Fill with mean\n",
    "                        \n",
    "                    else:    # Skewed numerical feature\n",
    "                        self.df.loc[:, feature] = self.df[feature].fillna(self.df[feature].median()).copy()    # Fill with median\n",
    "                        \n",
    "            else:    # Categorical feature\n",
    "                if self.descriptor[1][feature]>5:    # Null values between 5-30%\n",
    "                    self.knnImpute(self.df,self.descriptor,feature)    # Use KNN\n",
    "                    \n",
    "                else:    # Null values between less than 5%\n",
    "                    self.df.loc[:, feature] = self.df[feature].fillna(self.df[feature].mode().iloc[0]).copy()   # Fill with mode\n",
    "\n",
    "                    \n",
    "        self.descriptor=self.generateDescriptor()    # Remake descriptor df\n",
    "        return self\n",
    "\n",
    "    def transform(self):\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb400d5c-8eae-4b25-a367-5465ea1732ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre=Preprocessor(df)\n",
    "df1=pre.fillNull().transform()\n",
    "df1.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a9a82c-7511-4e02-b40d-d42c1a2ecc8a",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60690cf-6ede-49ca-8069-b9b74b1352c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "\n",
    "class FeatureEngineering:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    @staticmethod\n",
    "    def safe_parse_date(date_str):\n",
    "        try:\n",
    "            return parser.parse(date_str)\n",
    "        except (ValueError, TypeError):\n",
    "            return None\n",
    "\n",
    "    def extract_datetime_features(self):\n",
    "        datetime_cols = self.df.select_dtypes(include=['object']).columns.tolist()\n",
    "        datetime_cols = [col for col in datetime_cols if self.df[col].str.contains(r'\\d', na=False, regex=True).any()]\n",
    "        \n",
    "        new_features = {}\n",
    "\n",
    "        for col in datetime_cols:\n",
    "            self.df[col] = self.df[col].apply(lambda x: FeatureEngineering.safe_parse_date(x) if pd.notna(x) else None)\n",
    "            self.df[col] = pd.to_datetime(self.df[col], errors='coerce')\n",
    "\n",
    "            valid_rows = self.df[col].notna()\n",
    "            if valid_rows.sum() < 0.3 * self.df.shape[0]:  # Keep only columns with enough valid dates\n",
    "                continue\n",
    "\n",
    "            new_features[f\"{col}_year\"] = self.df[col].dt.year\n",
    "            new_features[f\"{col}_month\"] = self.df[col].dt.month\n",
    "            new_features[f\"{col}_day\"] = self.df[col].dt.day\n",
    "            new_features[f\"{col}_weekday\"] = self.df[col].dt.weekday\n",
    "            new_features[f\"{col}_hour\"] = self.df[col].dt.hour\n",
    "            self.df.drop(columns=[col], inplace=True)\n",
    "\n",
    "        if new_features:\n",
    "            self.df = pd.concat([self.df, pd.DataFrame(new_features, index=self.df.index)], axis=1)  # Efficient joining\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def extract_text_features(self):\n",
    "        text_cols = self.df.select_dtypes(include=['object']).columns\n",
    "        new_features = {}\n",
    "\n",
    "        for col in text_cols:\n",
    "            if self.df[col].isna().all():\n",
    "                continue\n",
    "            new_features[f\"{col}_char_count\"] = self.df[col].astype(str).apply(len)\n",
    "            new_features[f\"{col}_word_count\"] = self.df[col].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "        if new_features:\n",
    "            self.df = self.df.assign(**new_features)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_interaction_features(self):\n",
    "        num_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        new_features = {}\n",
    "    \n",
    "        if len(num_cols) > 1:\n",
    "            for i in range(len(num_cols)):\n",
    "                for j in range(i + 1, len(num_cols)):\n",
    "                    col1, col2 = num_cols[i], num_cols[j]\n",
    "    \n",
    "                    # Basic multiplicative interaction\n",
    "                    new_features[f\"{col1}_x_{col2}\"] = self.df[col1].fillna(0) * self.df[col2].fillna(0)\n",
    "                    \n",
    "                    # Additive interaction\n",
    "                    new_features[f\"{col1}_plus_{col2}\"] = self.df[col1].fillna(0) + self.df[col2].fillna(0)\n",
    "                    \n",
    "                    # Ratio interaction (avoid division by zero)\n",
    "                    new_features[f\"{col1}_div_{col2}\"] = self.df[col1] / (self.df[col2] + 1e-9)\n",
    "                    new_features[f\"{col2}_div_{col1}\"] = self.df[col2] / (self.df[col1] + 1e-9)\n",
    "    \n",
    "        if new_features:\n",
    "            self.df = pd.concat([self.df, pd.DataFrame(new_features, index=self.df.index)], axis=1).copy()\n",
    "        return self\n",
    "\n",
    "\n",
    "    def create_statistical_features(self):\n",
    "        num_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        if len(num_cols) == 0:\n",
    "            return self\n",
    "\n",
    "        self.df[\"num_mean\"] = self.df[num_cols].mean(axis=1)\n",
    "        self.df[\"num_std\"] = self.df[num_cols].std(axis=1)\n",
    "        self.df[\"num_median\"] = self.df[num_cols].median(axis=1)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def encode_categorical_features(self):\n",
    "        cat_cols = self.df.select_dtypes(include=['object']).columns\n",
    "        new_features = {}\n",
    "\n",
    "        for col in cat_cols:\n",
    "            counts = self.df[col].value_counts().to_dict()\n",
    "            freqs = self.df[col].map(self.df[col].value_counts(normalize=True))\n",
    "            \n",
    "            new_features[f\"{col}_count\"] = counts\n",
    "            new_features[f\"{col}_freq\"] = freqs\n",
    "\n",
    "        if new_features:\n",
    "            self.df = self.df.assign(**new_features)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self):\n",
    "        self.df.dropna(axis=1, how='any', inplace=True)  # Drops all columns with any NaN values\n",
    "        return self.df\n",
    "\n",
    "\n",
    "    def automated_feature_engineering(self):\n",
    "        return (\n",
    "            self.extract_datetime_features()\n",
    "            .extract_text_features()\n",
    "            .create_interaction_features()\n",
    "            .create_statistical_features()\n",
    "            .encode_categorical_features()\n",
    "            .transform()\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3cb1d8a-7811-45cd-b38d-c78e2688e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureEngineering(df1)\n",
    "df2 = fe.automated_feature_engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c143cfd-ee27-4bfd-bcf2-34ce043c3743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 334)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c33f122-900c-4f66-9b82-c6bd55c1360f",
   "metadata": {},
   "source": [
    "TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba4d3640-537d-4bd0-8fca-1e6c9f3162a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def X_y_split(self, target_feature):\n",
    "        if target_feature in self.df.columns:\n",
    "            y = self.df[target_feature]\n",
    "            X = self.df.drop(columns=[target_feature])\n",
    "            return X, y\n",
    "        else:\n",
    "            print(f\"'{target_feature}' is not a feature of the given dataset.\")\n",
    "            return None, None\n",
    "\n",
    "    def train_test_split(self, X, y, test_size=0.2, random_state=42):\n",
    "        np.random.seed(random_state)\n",
    "        indices = np.random.permutation(len(X))\n",
    "\n",
    "        test_count = int(len(X) * test_size)\n",
    "        test_idx, train_idx = indices[:test_count], indices[test_count:]\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "232031d9-88b8-40db-adb1-c516143f6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp=Split(df2)\n",
    "X,y=sp.X_y_split('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f50a38f-4ee9-4116-82ff-b9406a84e177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_char_count</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked_char_count_x_Embarked_word_count</th>\n",
       "      <th>Embarked_char_count_plus_Embarked_word_count</th>\n",
       "      <th>Embarked_char_count_div_Embarked_word_count</th>\n",
       "      <th>Embarked_word_count_div_Embarked_char_count</th>\n",
       "      <th>num_mean</th>\n",
       "      <th>num_std</th>\n",
       "      <th>num_median</th>\n",
       "      <th>Name_freq</th>\n",
       "      <th>Sex_freq</th>\n",
       "      <th>Embarked_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.200000e+08</td>\n",
       "      <td>2.585450e+09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.725028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.577948e+08</td>\n",
       "      <td>5.305538e+09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>0.188552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "\n",
       "      Sex   Age  SibSp  Parch     Fare Embarked  Name_char_count  ...  \\\n",
       "0    male  22.0      1      0   7.2500        S               23  ...   \n",
       "1  female  38.0      1      0  71.2833        C               51  ...   \n",
       "\n",
       "   Embarked_char_count_x_Embarked_word_count  \\\n",
       "0                                          1   \n",
       "1                                          1   \n",
       "\n",
       "   Embarked_char_count_plus_Embarked_word_count  \\\n",
       "0                                             2   \n",
       "1                                             2   \n",
       "\n",
       "   Embarked_char_count_div_Embarked_word_count  \\\n",
       "0                                          1.0   \n",
       "1                                          1.0   \n",
       "\n",
       "   Embarked_word_count_div_Embarked_char_count      num_mean       num_std  \\\n",
       "0                                          1.0  4.200000e+08  2.585450e+09   \n",
       "1                                          1.0  5.577948e+08  5.305538e+09   \n",
       "\n",
       "   num_median  Name_freq  Sex_freq  Embarked_freq  \n",
       "0         3.0   0.001122  0.647587       0.725028  \n",
       "1         2.0   0.001122  0.352413       0.188552  \n",
       "\n",
       "[2 rows x 333 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2997e3c-f950-4fe4-896d-86d78261090d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7820206-a22f-4a21-a778-9d5dc6d436ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=sp.train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e50d32e8-8592-4746-a9da-e045b3aaf7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(713, 333)\n",
      "(713,)\n",
      "(178, 333)\n",
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3309f69-0956-4da0-98c2-ff1473fc8de3",
   "metadata": {},
   "source": [
    "ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40530afc-911a-437a-80bf-e42e2b96af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoder:\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train.copy()\n",
    "        self.X_test = X_test.copy()\n",
    "        self.y_train = y_train.copy()\n",
    "        self.y_test = y_test.copy()\n",
    "        self.encoding_type = self.generateEncodingType()\n",
    "\n",
    "    def generateEncodingType(self): \n",
    "        categorical_columns = self.X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "        encoding_type = {}\n",
    "        for column in categorical_columns:\n",
    "            if self.X_train[column].nunique() < 10:\n",
    "                encoding_type[column] = 'OHE'\n",
    "            else:\n",
    "                encoding_type[column] = 'frequency'\n",
    "        return encoding_type\n",
    "\n",
    "    def oneHotEncoding(self, features):\n",
    "        self.X_train = pd.get_dummies(self.X_train, columns=features, drop_first=True)\n",
    "        self.X_test = pd.get_dummies(self.X_test, columns=features, drop_first=True)\n",
    "        self.X_test = self.X_test.reindex(columns=self.X_train.columns, fill_value=0)  # Align test with train\n",
    "\n",
    "    def frequencyEncoding(self, features):\n",
    "        for feature in features:\n",
    "            freqs = self.X_train[feature].value_counts(normalize=True)\n",
    "            self.X_train[feature + '_freq'] = self.X_train[feature].map(freqs)\n",
    "            self.X_test[feature + '_freq'] = self.X_test[feature].map(freqs).fillna(0)\n",
    "        self.X_train.drop(columns=features, inplace=True)\n",
    "        self.X_test.drop(columns=features, inplace=True)\n",
    "\n",
    "    def encodeInput(self):\n",
    "        OHE = []\n",
    "        freq = []\n",
    "        for feature in self.encoding_type.keys():  \n",
    "            if self.encoding_type[feature] == 'OHE':\n",
    "                OHE.append(feature)\n",
    "            else:\n",
    "                freq.append(feature)\n",
    "\n",
    "        self.oneHotEncoding(OHE)\n",
    "        self.frequencyEncoding(freq)\n",
    "        return self.X_train, self.X_test\n",
    "\n",
    "    def encodeOutput(self):\n",
    "        if self.y_train.dtype == 'object':\n",
    "            unique_classes = self.y_train.unique()\n",
    "            class_mapping = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "            self.y_train = self.y_train.map(class_mapping)\n",
    "            self.y_test = self.y_test.map(lambda x: class_mapping.get(x, -1))  # -1 --> unseen classes \n",
    "        return self.y_train, self.y_test\n",
    "\n",
    "\n",
    "class TargetEncoder:\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train.copy()\n",
    "        self.X_test = X_test.copy()\n",
    "        self.y_train = y_train.copy()\n",
    "        self.y_test = y_test.copy()\n",
    "        self.target_features = self.X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "        self.encoding_map = {}\n",
    "\n",
    "    def fit(self, features):\n",
    "        df_train = self.X_train.copy()\n",
    "        df_train[\"target\"] = self.y_train  # Temporarily add y_train to X_train\n",
    "\n",
    "        for feature in features:\n",
    "            means = df_train.groupby(feature)[\"target\"].mean()  # Now \"target\" exists in df_train\n",
    "            self.encoding_map[feature] = means.to_dict()\n",
    "\n",
    "    def transform(self, X, features):\n",
    "        X_encoded = X.copy()\n",
    "        for feature in features:\n",
    "            X_encoded[feature + '_target'] = X_encoded[feature].map(self.encoding_map.get(feature, {})).fillna(self.y_train.mean())\n",
    "        X_encoded.drop(columns=features, inplace=True)\n",
    "        return X_encoded\n",
    "\n",
    "    def encodeInput(self):\n",
    "        self.fit(self.target_features)\n",
    "        self.X_train = self.transform(self.X_train, self.target_features)\n",
    "        self.X_test = self.transform(self.X_test, self.target_features)\n",
    "        return self.X_train, self.X_test\n",
    "\n",
    "    def encodeOutput(self):\n",
    "        if self.y_train.dtype == 'object':\n",
    "            unique_classes = self.y_train.unique()\n",
    "            class_mapping = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "            self.y_train = self.y_train.map(class_mapping)\n",
    "            self.y_test = self.y_test.map(lambda x: class_mapping.get(x, -1))  # Assign -1 to unseen classes \n",
    "        return self.y_train, self.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ce08e9d-d570-4ffc-bd5d-5bd5c57466df",
   "metadata": {},
   "outputs": [],
   "source": [
    "se=SimpleEncoder(X_train,X_test,y_train,y_test)\n",
    "Xtrain_se,Xtest_se=se.encodeInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cbc1979-0015-447f-bbad-c0ced7352c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "te=TargetEncoder(X_train,X_test,y_train,y_test)\n",
    "Xtrain_te,Xtest_te=te.encodeInput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef9a72-32cb-437b-bc75-c1473ea93f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
